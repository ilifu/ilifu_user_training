<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Slurm ‚Äî ilifu Online Training Session 1</title>
    <meta name="description"
        content="Slurm job submission tutorial for ilifu HPC cluster users. Session 1, Tutorial 2.">

    <!-- Reveal.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/reveal.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/theme/white.min.css" id="theme">

    <!-- Highlight.js for code -->
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/plugin/highlight/monokai.min.css">

    <!-- Asciinema Player -->

    <link rel="stylesheet" type="text/css" href="resources/asciinema-player.css" />

    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" href="resources/theme.css">
</head>

<body>

    <!-- Right-side sponsor/funder logos (persistent across all slides) -->
    <div class="logo-sidebar">
        <img src="assets/cbio_logo.png" alt="CBIO" title="CBIO ‚Äî Computational Biology, UCT"
            onerror="this.outerHTML='<div style=&quot;width:60px;height:40px;background:#eef2f7;border:1px solid #ccc;border-radius:4px;display:flex;align-items:center;justify-content:center;font-size:10px;font-weight:600;color:#2b579a&quot;>CBIO</div>'">
        <img src="assets/idia_logo.png" alt="IDIA" title="IDIA ‚Äî Institute for Data Intensive Astronomy"
            onerror="this.outerHTML='<div style=&quot;width:60px;height:40px;background:#eef2f7;border:1px solid #ccc;border-radius:4px;display:flex;align-items:center;justify-content:center;font-size:10px;font-weight:600;color:#2b579a&quot;>IDIA</div>'">
        <img src="https://upload.wikimedia.org/wikipedia/en/thumb/7/7c/University_of_Cape_Town_logo.svg/200px-University_of_Cape_Town_logo.svg.png"
            alt="UCT" title="University of Cape Town"
            onerror="this.outerHTML='<div style=&quot;width:60px;height:40px;background:#eef2f7;border:1px solid #ccc;border-radius:4px;display:flex;align-items:center;justify-content:center;font-size:10px;font-weight:600;color:#2b579a&quot;>UCT</div>'">
    </div>

    <div class="reveal">
        <div class="slides">

            <!-- <section>
                <div class="slide-header">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/200px-Slurm_logo.svg.png"
                        alt="Slurm"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>Slurm Workload Manager</span>'">
                    <h3>Title</h3>
                    <img src="https://www.ilifu.ac.za/wp-content/uploads/2023/03/ILIFU-LOGO-RGB-Landscape-1-768x327.png"
                        alt="ilifu"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>ilifu</span>'">
                </div>

                <p>Content</p>
            </section> -->

            <!-- =============================== -->
            <!-- SLIDE 1: Title                   -->
            <!-- =============================== -->
            <section class="title-slide">
                <h1>ilifu Online Training</h1>
                <h1 class="subtitle">Session 1: Introduction to Slurm</h1>
                <h1 class="subtitle"><small>24 February 2026</small></h1>
                <h2 class="meta">
                    <small>Dane Kennedy ¬∑ ilifu Bioinformatics Support<br>
                        University of Cape Town
                    </small>
                </h2>

                <div class="slide-footer">
                    <a href="https://kennedydane.github.io/ilifu/training/session1/tutorial2/presentation/">Link to
                        presentation</a>
                </div>

                <aside class="notes">
                    Welcome to Session 1 of ilifu online training. Today we'll cover Slurm job submission ‚Äî
                    from your first "Hello World" to advanced batch scripts with containers.
                </aside>
            </section>

            <section>
                <div class="slide-header">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/200px-Slurm_logo.svg.png"
                        alt="Slurm"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>Slurm Workload Manager</span>'">
                    <h3>What is Slurm?</h3>
                    <img src="https://www.ilifu.ac.za/wp-content/uploads/2023/03/ILIFU-LOGO-RGB-Landscape-1-768x327.png"
                        alt="ilifu"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>ilifu</span>'">
                </div>

                <h4>Job Scheduling & Cluster Management Tool</h4>
                <div class="info-box">
                    An open-source <strong>job scheduling &amp; cluster management tool</strong>. You submit work from
                    the login
                    node; Slurm allocates compute resources and runs your jobs when they're available.
                </div>
                <div class="arch-diagram">
                    <div class="arch-box login">
                        <div class="box-title">üñ•Ô∏è Login Node</div>
                        <div>SSH access<br><code>slurm.ilifu.ac.za</code><br>Submit jobs &amp; manage files</div>
                    </div>
                    <div class="arch-arrow">‚Üí</div>
                    <div class="arch-box scheduler">
                        <div class="box-title">‚öôÔ∏è Scheduler</div>
                        <div>Queue management<br>Resource allocation<br>Accounting</div>
                    </div>
                    <div class="arch-arrow">‚Üí</div>
                    <div class="arch-box compute">
                        <div class="box-title">üîß Compute Nodes</div>
                        <div>Run analysis/simulation<br>Containers &amp; modules<br>Where your jobs execute</div>
                    </div>
                </div>
                <ul>
                    <li class="fragment">Login Node
                        <ul>
                            <li>Accessed via ssh (<code>$ ssh &lt;username&gt;@slurm.ilifu.ac.za</code>)</li>
                            <li>Submit jobs and basic file management</li>
                        </ul>
                    </li>
                    <li class="fragment">Scheduler and Accounting Database
                        <ul>
                            <li>Manage jobs, Partitions and Nodes</li>
                            <li>Accounting</li>
                        </ul>
                    </li>
                    <li class="fragment">Compute Nodes
                        <ul>
                            <li>Where your analysis / simulation runs (inside of a slurm job)</li>
                            <li>Software available via singularity containers or modules</li>
                        </ul>
                    </li>

                </ul>

                <div class="slide-footer">
                    <a href="https://slurm.schedmd.com/overview.html">Slurm Overview</a>
                    <a href="https://docs.ilifu.ac.za/#/">ilifu documentation</a>
                    <a href="https://docs.ilifu.ac.za/#/getting_started/submit_job_slurm">Submit a Slurm Job</a>
                </div>
                <aside class="notes">
                    What is slurm? Slurm is an open-source workload manager or scheduler.<br />

                    What it is does is allow you to submit computing tasks (or jobs) to a computing cluster. A computing
                    cluster is a collection of computers / servers (which we usually call ‚Äúnodes‚Äù) together with some
                    storage all linked together with a fast network. The workload manager figures out when and where
                    those jobs can run; and keeps a record of their resource usage for accounting purposes.<br />

                    From a user‚Äôs perspective there are three main components that you should be aware of:<br />

                    Firstly there is the login node ‚Äî apart from Jupyter, this is usually your first point of contact
                    with the cluster and the place where you will do most of your interactions. It is not a server to
                    use for big computing tasks; but rather it‚Äôs a place for administrative tasks such as submitting
                    jobs, editing scripts and light management of data. The login node is shared with all the users of
                    the cluster ‚Äî so any misuse impacts others negatively ‚Äî so we monitor it closely and are quite
                    strict about how it‚Äôs used.<br />

                    Secondly there is slurm itself which has 3 key functions:<br />s
                    <ul>
                        <li>Slurm Allocates access to resources for users. In other words this is reserving memory and
                            CPU
                            resources on the compute nodes for specific jobs.</li>
                        <li>Slurm Provides a framework for starting, executing, and monitoring work or jobs. These are
                            the
                            commands I will cover a little bit later.</li>
                        <li>Managing a queue for pending work. So when you submit a job, it first sits in a queue and
                            waits for
                            its turn to run. In slurm these queues are called partitions and there are several different
                            ones
                            you can choose from. And I‚Äôll cover that in the next slide.</li>
                    </ul>

                    Finally there are the compute nodes ‚Äî these are bigger servers and the place where computing jobs
                    are run. Once you‚Äôre running something on a node, the resources you‚Äôve requested are allocated to
                    you. This means that nobody else can interfere with the running of your software, but the flip side
                    of that is that you should be as accurate as possible when specifying those resources. This is
                    covered in more detail in Session 2.<br />

                </aside>
            </section>

            <section>
                <div class="slide-header">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/200px-Slurm_logo.svg.png"
                        alt="Slurm"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>Slurm Workload Manager</span>'">
                    <h3>Specific node / partition use cases</h3>
                    <img src="https://www.ilifu.ac.za/wp-content/uploads/2023/03/ILIFU-LOGO-RGB-Landscape-1-768x327.png"
                        alt="ilifu"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>ilifu</span>'">
                </div>

                <table>
                    <thead>
                        <tr>
                            <th>Node / Partition</th>
                            <th>Use Case</th>
                            <th>Resources</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>slurm.ilifu.ac.za</code>
                                <!-- / <span class="badge badge-gray">Login</span> -->
                            </td>
                            <td>SLURM &amp; bash commands (<code>cd</code>, <code>mkdir</code>, <code>sbatch</code>)
                            </td>
                            <td>‚Äî</td>
                        </tr>
                        <tr>
                            <td><code>compute-001</code> / <span class="badge badge-blue">Devel</span></td>
                            <td>Development, debugging, testing, interactive jobs</td>
                            <td>1 √ó (32 cores, ~232 GiB)</td>
                        </tr>
                        <tr>
                            <td><code>jupyter-0[01-14]</code> / <span class="badge badge-blue">Jupyter</span></td>
                            <td>JupyterLab ‚Äî interactive development/analysis</td>
                            <td>14 √ó (32 cores, ~232 GiB)</td>
                        </tr>
                        <tr>
                            <td><code>compute-0[02-86]</code> / <span class="badge badge-green">Main</span></td>
                            <td>Stable, heavy computation</td>
                            <td>85 √ó (32 cores, ~232 GiB)</td>
                        </tr>
                        <tr>
                            <td><code>highmem-00[1-8]</code> / <span class="badge badge-red">HighMem</span></td>
                            <td>High memory jobs</td>
                            <td>6 √ó (32 cores, 500 GiB) + 1 √ó (32 cores, 1 TiB) + 1 √ó (96 cores, 1.5 TiB)</td>
                        </tr>
                        <tr>
                            <td><code>gpu-00[1-7]</code> / <span class="badge badge-red">GPU</span></td>
                            <td>GPU-accelerated workloads</td>
                            <td>7 √ó (32 cores, ~232 GiB + NVIDIA GPUs)</td>
                        </tr>
                    </tbody>
                </table>

                <div class="slide-footer">
                    <a href="https://docs.ilifu.ac.za/#/tech_docs/running_jobs?id=available-resources">Available
                        Resources</a>
                </div>
                <aside class="notes">
                    This table shows a summary of the available partitions and the resources available on each
                    partition.

                    Starting with the login node, as mentioned earlier, this is where you'll perform basic
                    administrative tasks, such as running bash and Slurm commands.

                    Jupyter and Development Partition: Think of this as a development space for testing new software,
                    plotting results, building workflows, and debugging.

                    Main Partition: This is where most stable and computationally intensive jobs are executed. (By
                    stable I mean the code isn‚Äôt changing ‚Äî it is an established process that only differs in input and
                    output). Parallelism may be possible, or jobs may be split into smaller tasks.

                    HighMem and GPU Partition: Although not covered in this presentation, the HighMem partition is
                    designed for single, high-memory jobs that can't be split up. We'll dive deeper into this topic in a
                    later Session.

                    While many users use Jupyter as their primary interface with the compute resources we do, as a
                    general rule, prefer it if users use one of the Main, Highmem or GPU nodes as this tends to result
                    in more efficient use of resources. This is because interactive jobs such as jupyter tend to have
                    longer periods where resources are idle.

                    When running jobs on the cluster, the default partition is ‚ÄúMain‚Äù and unless you explicitly need
                    something else, this is probably the one you‚Äôll want to use. The nodes here have 32 CPUs or cores
                    and about 232GiB of available memory. We also have 3 HighMem nodes, 2 of which have 32 cores but
                    503GiB of RAM and one very large node with about 1¬ΩTiB RAM and 96 cores. We also have 7 GPU nodes
                    which are similar to the nodes in Main, but have up to two GPUs available. The we have the Devel
                    partition which you can use for interactive jobs (which are explained later) and then there‚Äôs the
                    Jupyter partition, which you only ever implicitly use if you‚Äôre using Jupyter.


                </aside>
            </section>

            <section>
                <div class="slide-header">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/200px-Slurm_logo.svg.png"
                        alt="Slurm"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>Slurm Workload Manager</span>'">
                    <h3>Interacting with the Slurm Cluster</h3>
                    <img src="https://www.ilifu.ac.za/wp-content/uploads/2023/03/ILIFU-LOGO-RGB-Landscape-1-768x327.png"
                        alt="ilifu"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>ilifu</span>'">
                </div>

                <div class="columns">
                    <div class="col">
                        <h3>üåê Web Access</h3>
                        <p><a href="https://jupyter.ilifu.ac.za" target="_blank">https://jupyter.ilifu.ac.za</a></p>
                        <video controls muted poster="demos/jupyter.png">
                            <source src="demos/jupyter.mp4" type="video/mp4">
                        </video>
                        <div class="info-box tip" style="margin-top: 0.8em;">
                            <strong>üí° Remember to end your session:</strong> File ‚Üí Hub Control Panel ‚Üí Stop My
                            Server.
                        </div>
                    </div>
                    <div class="col">
                        <h3>üíª CLI Access</h3>
                        <pre><code class="language-bash">ssh &lt;username&gt;@slurm.ilifu.ac.za</code></pre>
                        <div id="demo-login">
                        </div>
                    </div>
                </div>
                <div class="slide-footer">
                    <a href="https://jupyter.ilifu.ac.za">https://jupyter.ilifu.ac.za</a>
                    <a href="https://docs.ilifu.ac.za/#/getting_started/access_ilifu">Logging into ilifu</a>
                    <a href="https://docs.ilifu.ac.za/#/getting_started/ssh">SSH Keys</a>
                </div>
                <aside class="notes">
                    This slide shows the two primary ways one interacts with the cluster.<br /><br />

                    On the left we see the jupyter interface that Jeremy showed you earlier. The thing I really just
                    wanted to point out is that on the backend jupyter is actually running as a slurm job on a regular
                    compute node. So we have JupyterHub running as a service on its own node, but it submits a job to
                    slurm on your behalf and then acts as a proxy between your jupyter job and your browser.<br /><br />

                    Then the image on the left illustrates more what I‚Äôll be demonstrating shortly and that‚Äôs the shell
                    or command line interface (CLI for short) and how one uses that to interact with the cluster.

                </aside>
            </section>
            <section>
                <div class="slide-header">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/200px-Slurm_logo.svg.png"
                        alt="Slurm"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>Slurm Workload Manager</span>'">
                    <h3>CLI user commands</h3>
                    <img src="https://www.ilifu.ac.za/wp-content/uploads/2023/03/ILIFU-LOGO-RGB-Landscape-1-768x327.png"
                        alt="ilifu"
                        onerror="this.outerHTML='<span style=&quot;font-weight:700;color:#2b579a;font-size:0.9em&quot;>ilifu</span>'">
                </div>

                <pre><code data-trim class="language-bash" data-line-numbers="1-8|2|3-4|5|6|7-8">
ssh &lt;username&gt;@slurm.ilifu.ac.za  # connect to login node
sinfo                             # show partition information
squeue                            # show all job information
squeue -u $USER                   # show only your jobs
sbatch your_job_script.sh         # submit a job
scancel                           # cancel a job
man sbatch                        # show the manual page for a command
sbatch --help                     # show the help page for a command
                </code></pre>

                <div id="demo-cli" style="flex: 1; min-height: 0; width: 100%;"></div>

                <div class="slide-footer">
                    <a href="https://slurm.schedmd.com/quickstart.html">Slurm Quick Start User Guide</a>
                </div>

                <aside class="notes">
                    First off one has to connect to the login node and one generally uses the `ssh` command if you‚Äôre
                    working on linux / Mac or some SSH client in Windows.<br /><br />

                    Once you have landed on the login node, these are the basic slurm commands that are useful to get
                    you
                    going. These commands allow you to get submit/monitor jobs as well as get information about the
                    state
                    of the cluster. I‚Äôll demo all of these commands later, but let me give you a quick
                    rundown.<br /><br />

                    Sinfo ‚Äî this gives you information about the partitions (sometimes called queues). It shows you the
                    number of nodes available and their state like: are they free, partially used or fully allocated to
                    jobs.<br /><br />

                    Squeue ‚Äî this gives you information about all the jobs that have been submitted to the cluster and
                    have not finished running yet. You can filter this information in various ways, for example one can
                    filter by user ‚Äî so if you wanted to show only your jobs you can add this ‚Äú-u‚Äù parameter with your
                    username.<br /><br />

                    Sbatch is how you submit a regular job on the cluster. When you run it (and there are no problems in
                    your script) it gives you a job ID.<br /><br />

                    Scancel is to cancel a queued or running job.<br /><br />

                    There are a handful of other ways to submit jobs but these will be covered later in one of the
                    advanced training sessions.

                </aside>


            </section>

        </div><!-- /.slides -->
    </div><!-- /.reveal -->

    <!-- Reveal.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/reveal.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/plugin/highlight/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/plugin/notes/notes.min.js"></script>

    <!-- Asciinema Player -->
    <script src="resources/asciinema-player.min.js"></script>

    <script>
        // Initialize Reveal.js
        Reveal.initialize({
            hash: true,
            slideNumber: 'c/t',
            transition: 'slide',
            transitionSpeed: 'default',
            controlsTutorial: true,
            progress: true,
            center: false,
            width: 1920,
            height: 1080,
            margin: 0,
            plugins: [RevealHighlight, RevealNotes]
        });

        AsciinemaPlayer.create('demos/login.cast', document.getElementById('demo-login'), {
            autoPlay: false,
            loop: false,
            controls: true,
            // theme: 'monokai',
            speed: 1.5,
            poster: 'npt:0:6',
            autoplay: 1,
        });
        AsciinemaPlayer.create('demos/cli.cast', document.getElementById('demo-cli'), {
            autoPlay: false,
            loop: false,
            controls: true,
            // theme: 'monokai',
            speed: 1.5,
            speed: 1.5,
            poster: 'npt:0:5',
            autoplay: 1,
            fit: 'both'
        });
    </script>

</body>

</html>